{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import tempfile\n",
    "from pdf2image import convert_from_path\n",
    "import img2pdf\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "# from rainbow_html_transformer_old import HTMLToTextWithMarkdownTables\n",
    "from rainbow_html_transformer import HTMLToTextWithMarkdownTables\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경변수에서 API 키 가져오기\n",
    "API_KEY = os.getenv(\"UPSTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_pages(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path, max_pages=3):\n",
    "    extracted_text = []\n",
    "    html_transformer = HTMLToTextWithMarkdownTables()\n",
    "    \n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, first_page=1, last_page=max_pages)\n",
    "        \n",
    "        print(f\"Processing {len(images)} pages...\")\n",
    "        for i, img in enumerate(tqdm(images, desc=\"Processing pages\", unit=\"page\")):\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_file:\n",
    "                img.save(temp_file, format=\"PNG\")\n",
    "                temp_file_path = temp_file.name\n",
    "            \n",
    "            try:\n",
    "                loader = UpstageLayoutAnalysisLoader(\n",
    "                    file_path=temp_file_path,\n",
    "                    use_ocr=True\n",
    "                )\n",
    "                documents = loader.load()\n",
    "                \n",
    "                if not documents:\n",
    "                    print(f\"Warning: No content extracted from page {i+1}\")\n",
    "                    continue\n",
    "\n",
    "                page_content = \"\"\n",
    "                for doc in documents:\n",
    "                    if doc is None or not doc.page_content:\n",
    "                        print(f\"Warning: Empty document encountered for page {i+1}\")\n",
    "                        continue\n",
    "                    transformed_doc = html_transformer.transform_document(doc)\n",
    "                    page_content += transformed_doc.page_content\n",
    "\n",
    "                # 페이지 내용 정리\n",
    "                page_content = page_content.strip()\n",
    "                if page_content:\n",
    "                    page_content += f\"\\n\\n--- End of Page {i+1} ---\\n\\n\"\n",
    "                    extracted_text.append(page_content)\n",
    "                else:\n",
    "                    print(f\"Warning: No content extracted from page {i+1}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {i+1}: {e}\")\n",
    "            finally:\n",
    "                os.unlink(temp_file_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path} with OCR: {e}\")\n",
    "    \n",
    "    if not extracted_text:\n",
    "        print(\"Warning: No text was extracted from the document.\")\n",
    "    \n",
    "    return ''.join(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_async_ocr(pdf_path, max_pages=1000):\n",
    "    # api_key = \"YOUR_UPSTAGE_API_KEY\"\n",
    "    url = \"https://api.upstage.ai/v1/document-ai/async/layout-analysis\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        files = {\"document\": file}\n",
    "        data = {\"ocr\": \"true\"}\n",
    "        \n",
    "        # Submit the inference request\n",
    "        response = requests.post(url, headers=headers, files=files, data=data)\n",
    "        response.raise_for_status()\n",
    "        request_id = response.json()[\"request_id\"]\n",
    "    \n",
    "    # Poll for results\n",
    "    status_url = f\"https://api.upstage.ai/v1/document-ai/requests/{request_id}\"\n",
    "    while True:\n",
    "        response = requests.get(status_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        status_data = response.json()\n",
    "        \n",
    "        if status_data[\"status\"] == \"completed\":\n",
    "            break\n",
    "        elif status_data[\"status\"] == \"failed\":\n",
    "            raise Exception(f\"Processing failed: {status_data['failure_message']}\")\n",
    "        \n",
    "        time.sleep(10)  # Wait before polling again\n",
    "    \n",
    "    # Download and process results\n",
    "    extracted_text = []\n",
    "    for batch in status_data[\"batches\"]:\n",
    "        download_url = batch[\"download_url\"]\n",
    "        batch_response = requests.get(download_url)\n",
    "        batch_response.raise_for_status()\n",
    "        batch_data = batch_response.json()\n",
    "        \n",
    "        for page in batch_data[\"pages\"]:\n",
    "            page_content = \"\\n\".join([block[\"text\"] for block in page[\"blocks\"]])\n",
    "            extracted_text.append(page_content)\n",
    "            extracted_text.append(f\"\\n\\n--- End of Page {page['page_num']} ---\\n\\n\")\n",
    "    \n",
    "    return \"\".join(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예:\n",
    "# Layout Analysis API의 최대 페이지 제한인 100페이지 이상은 처리 불가\n",
    "folder_path = \"./raw_docs\"\n",
    "output_folder_path = \"./processed_txt\"\n",
    "# pdf_file_name = \"판매약관_ThePride신한참좋은치아보험PlusⅡ(무배당, 갱신형)_20240401_P252.pdf\"\n",
    "# pdf_file_name = \"SHL0165_The안심VIP저축보험Ⅱ(무배당)_P116.pdf\"\n",
    "# pdf_file_name = \"DB자산관리_약관_20240401_P22.pdf\"\n",
    "# pdf_file_name = \"IRP자산관리_약관(기업형)_20240401_P24.pdf\"\n",
    "# pdf_file_name = \"./상품/판매약관_신한(간편가입)모아더드림종신보험(무배당, 해약환급금 일부지급형)_20240610.pdf\"\n",
    "pdf_file_name = \"./상품2/SHL0068_신한진심을품은대출안심보장보험(무배당).pdf\"\n",
    "\n",
    "print(f\"Processing file : {pdf_file_name}\")\n",
    "pdf_path = os.path.join(folder_path, pdf_file_name)\n",
    "\n",
    "max_pages = get_pdf_pages(pdf_path)\n",
    "ocr_text = extract_text_with_ocr(pdf_path, max_pages)\n",
    "\n",
    "# 텍스트 파일로 저장\n",
    "output_file_name = os.path.splitext(os.path.basename(pdf_file_name))[0] + \".txt\"\n",
    "output_path = os.path.join(output_folder_path, output_file_name)\n",
    "\n",
    "# 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(ocr_text)\n",
    "\n",
    "print(f\"OCR text saved to: {output_path}\")\n",
    "\n",
    "# 저장된 텍스트 출력 (선택사항)\n",
    "print(\"Extracted text:\")\n",
    "print(ocr_text[:500] + \"...\")  # 처음 500자만 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
